[{"body":"  .td-sidebar-toc { display: none !important; } .diagram { padding-right: 20px; }   var main = document.querySelector('main'); console.log(main) main.classList.remove('col-xl-8'); main.classList.add('col-xl-10');   Components Opni Monitoring Cluster  The Opni Monitoring cluster is the cluster in which the Opni Monitoring control-plane components are installed. This is the central cluster where all downstream clusters send their metrics to. Deployed in this cluster are the following components:   Opni Gateway   Cortex   Grafana   Etcd   (optional) Opni Agent   Downstream Clusters  Downstream clusters are the clusters that send their metrics to the Opni Monitoring cluster. Deployed in these clusters are the following components:   Opni Agent   Prometheus Agent   OpenID Provider  A production deployment of Opni Monitoring must use an OpenID Provider to authenticate users. The Grafana dashboard deployed in the Opni Monitoring cluster will be configured to use the OpenID Provider for user login. Support for other authentication mechanisms (LDAP, SAML, etc.) may be added in the future. Long-Term Storage  A production deployment of Opni Monitoring should be configured to use long-term metric storage. For example, this could be an S3-compatible object storage service. ","categories":"","description":"","excerpt":"  .td-sidebar-toc { display: none !important; } .diagram { …","ref":"/opni-monitoring/architecture/","tags":"","title":""},{"body":"It is important to understand the following terms and phrases before you get started with Opni Monitoring:\nMulti-Cluster Multi-Cluster (as in “multi-cluster monitoring”) refers to operations that involve multiple independent Kubernetes clusters.\nMulti-Tenant/Multi-Tenancy A tenant refers to a user or group of users who share a common access with specific privileges to the software/data instance.\nIn the context of Opni Monitoring, “multi-tenancy” refers to the feature that allows multiple users to each have access to a different arbitrary subset of all available data.\nImportant In the Cortex documentation, the terms “tenant”, “user”, and “org” are used interchangeably, and all refer to what Opni Monitoring calls “clusters”.\nIn Cortex terminology, “multi-tenancy” refers to the ability to federate a single request across multiple [cortex] tenants (where “federation” refers to the aggregation of the results of several individual requests to appear as one).\n (Main|Upstream|Opni Monitoring) Cluster “Main Cluster”, “Upstream Cluster”, and “Opni Monitoring Cluster” all refer to the cluster where Opni Gateway, Cortex, and Grafana are installed. Metrics from all clusters are sent to the Opni Gateway in this cluster, and are processed and stored by Cortex.\nDownstream Cluster This refers to a cluster running the Opni Agent and Prometheus Agent which sends all its metrics (using Prometheus Remote-Write) to the main cluster.\nNote The Opni Agent and Prometheus Agent are often also installed into the main cluster, to scrape metrics from the Opni Gateway and Cortex. However, we would still refer to that cluster as the main cluster.  ","categories":"","description":"Definitions of commonly used terms and phrases","excerpt":"Definitions of commonly used terms and phrases","ref":"/opni-monitoring/architecture/terminology/","tags":"","title":"Terminology"},{"body":"This guide will walk you through setting up a “demo” Opni Monitoring installation. This setup is not production-ready. If that is what you are looking for, check out the full Installation guide.\nImportant Before proceeding, please read the section on Terminology to familiarize yourself with a few key terms.  Prerequisites Infrastructure   One main cluster where the Opni Monitoring control-plane components will be installed.\n The main cluster must be accessible to all downstream clusters from a persistent DNS name. For demo purposes, you can use sslip.io if you do not have a domain name available.    One or more downstream clusters which will be configured to send metrics to the main cluster\n  All clusters must have a default storage class available.\n  Dependencies   Install helmfile using your distribution’s package manager or from the GitHub release page.\n  Clone the opni-monitoring repo:\n$ git clone https://github.com/rancher/opni-monitoring   Setting up the main cluster DNS Configuration  Identify the DNS name of your main cluster. This will be referenced in the following sections as \u003cgateway_address\u003e. Configure A records such that \u003cgateway_address\u003e and grafana.\u003cgateway_address\u003e both route to the IP address of your main cluster’s load balancer (skip this step if you are using sslip.io or a similar service).  Chart configuration Inside the opni-monitoring repo, change directories to deploy/charts/opni-monitoring/custom. There are three template files in this directory which you will need to copy and edit before continuing.\n Copy cortex-template.yaml to cortex.yaml and leave it empty. Copy grafana-template.yaml to grafana.yaml and edit it as follows, substituting \u003cgateway_address\u003e:  grafana.ini:server:domain:\"grafana.\u003cgateway_address\u003e\"root_url:\"https://\u003cgateway_address\u003e\"auth.generic_oauth:client_id:\"grafana\"client_secret:\"supersecret\"# (this can be whatever you want)auth_url:\"http://\u003cgateway_address\u003e:4000/oauth2/authorize\"token_url:\"http://\u003cgateway_address\u003e:4000/oauth2/token\"api_url:\"http://\u003cgateway_address\u003e:4000/oauth2/userinfo\"allowed_domains:example.com# (this can be whatever you want, but remember it for later)role_attribute_path:grafana_roleuse_pkce:falsetls:- secretName:grafana-tls-keyshosts:- \"grafana.\u003cgateway_address\u003e\"ingress:enabled:truehosts:- \"grafana.\u003cgateway_address\u003e\"Copy opni-monitoring-template.yaml to opni-monitoring.yaml and edit it as follows, substituting \u003cgateway_address\u003e:  auth:provider:noauthnoauth:discovery:issuer:\"http://\u003cgateway_address\u003e:4000/oauth2\"clientID:grafanaclientSecret:supersecret# (this must match client_secret in grafana.yaml)redirectURI:\"https://grafana.\u003cgateway_address\u003e/login/generic_oauth\"managementAPIEndpoint:\"opni-monitoring-internal:11090\"port:4000gateway:hostname:\"\u003cgateway_address\u003e\"dnsNames:- \"\u003cgateway_address\u003e\"Chart Installation Inside the opni-monitoring repo, change directories to deploy/.\n Ensure your current kubeconfig points to the main cluster. Run helmfile apply Wait for all resources to become ready. This may take a few minutes.  Accessing the dashboard Once all the pods in the opni-monitoring namespace are running, open the web dashboard:\n Port-forward to the opni-monitoring-internal service:  kubectl -n opni-monitoring port-forward svc/opni-monitoring-internal management-web:management-web Open your browser to http://localhost:12080.  Adding a cluster First, let’s add the main cluster itself - this allows us to gather metrics from the Opni Gateway and Cortex. Follow these steps to add the cluster to Opni Monitoring:\nCreate a token Tokens are used to authenticate new clusters during the bootstrap process. To create one:\n Navigate to the Tokens tab in the sidebar Click Create Token Use the default fields, and click Create. The new token will appear in the table.  Token Expiration All tokens will expire after a certain amount of time. The default value is 10 minutes.  Add a cluster   Navigate to the Clusters tab in the sidebar\n  Click Add Cluster\n  In the Capabilities drop-down menu, select metrics\n  In the Token drop-down menu, select the token we just created. When a capability and token have been selected, an install command will appear below.\n  Check the box that says Install Prometheus Operator (however, if you already have Prometheus Operator installed on a cluster you want to add, leave it unchecked).\n  Click on the install command to copy it to the clipboard\n  In a terminal, ensure your KUBECONFIG environment variable or ~/.kube/config context points to the main cluster, then paste and run the command.\n  In a few seconds, you should see a green banner informing you that the cluster has been added. Click Finish to return to the cluster list.\n  ","categories":"","description":"","excerpt":"This guide will walk you through setting up a “demo” Opni Monitoring …","ref":"/opni-monitoring/quickstart/","tags":"","title":"Quick Start"},{"body":"","categories":"","description":"","excerpt":"","ref":"/opni-monitoring/installation/","tags":"","title":"Installation"},{"body":"","categories":"","description":"","excerpt":"","ref":"/opni-monitoring/authentication/","tags":"","title":"Authentication Strategies"},{"body":"","categories":"","description":"","excerpt":"","ref":"/opni-monitoring/configuration/","tags":"","title":"Advanced Configuration"},{"body":"","categories":"","description":"","excerpt":"","ref":"/opni-monitoring/troubleshooting/","tags":"","title":"Troubleshooting"},{"body":" This is a placeholder page that shows you how to use this template site.\n If your project has an API, configuration, or other reference - anything that users need to look up that’s at an even lower level than a single task - put (or link to it) here. You can serve and link to generated reference docs created using Doxygen, Javadoc, or other doc generation tools by putting them in your static/ directory. Find out more in Adding static content. For OpenAPI reference, Docsy also provides a Swagger UI layout and shortcode that renders Swagger UI using any OpenAPI YAML or JSON file as source.\n","categories":"","description":"Low level reference docs for your project.\n","excerpt":"Low level reference docs for your project.\n","ref":"/opni-monitoring/reference/","tags":["intro","reference"],"title":"Reference"},{"body":"Opni Monitoring is an open-source multi-cluster monitoring platform. It ingests Prometheus metrics from all your Kubernetes clusters and provides a centralized observability plane for your infrastructure. Use Opni Monitoring to visualize metrics from all your clusters at once, and give each of your users their own customized view using granular access control.\n⚡ Powered by Open-Source Opni Monitoring is completely free (as in freedom, and beer) Apache-licensed open-source software. It builds upon existing, ubiquitous open-source systems - Prometheus, Grafana, and Cortex - and extends them with a number of powerful enterprise features typically only found in SaaS platforms and other proprietery solutions.\n🔋 Batteries Included Opni Monitoring comes out of the box with all the tools you need to get started with multi-cluster monitoring. Manage your clusters and configure access control rules with the built-in dashboard, command-line interface, or REST API.\nOpni Monitoring is secure-by-default and uses a zero-trust architecture for inter-cluster communication, with no extra setup required.\n🔒 You Own Your Data With Opni Monitoring, you have complete control over how and where your data is stored. Metric storage is powered by Cortex, which provides comprehensive configuration options for data storage and retention. Several storage backends are available including S3 (cloud or self-hosted), Swift, and Kubernetes Persistent Volumes.\nGet Started  Try out Opni Monitoring in a demo environment with the Quick Start guide Install Opni Monitoring in a production environment with the Installation guide  ","categories":"","description":"","excerpt":"Opni Monitoring is an open-source multi-cluster monitoring platform. …","ref":"/opni-monitoring/","tags":"","title":""},{"body":"","categories":"","description":"","excerpt":"","ref":"/opni-monitoring/categories/","tags":"","title":"Categories"},{"body":"","categories":"","description":"","excerpt":"","ref":"/opni-monitoring/tags/intro/","tags":"","title":"intro"},{"body":"","categories":"","description":"","excerpt":"","ref":"/opni-monitoring/tags/reference/","tags":"","title":"reference"},{"body":"","categories":"","description":"","excerpt":"","ref":"/opni-monitoring/search/","tags":"","title":"Search Results"},{"body":"","categories":"","description":"","excerpt":"","ref":"/opni-monitoring/tags/","tags":"","title":"Tags"}]